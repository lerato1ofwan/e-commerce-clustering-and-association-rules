{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c4388c85",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import mode\n",
    "from sklearn.cluster import MiniBatchKMeans\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import random\n",
    "\n",
    "# Utility function for clean evaluation\n",
    "def evaluate_model(y_true, y_pred, model_name, target_names):\n",
    "    \"\"\"Prints classification report and plots confusion matrix.\"\"\"\n",
    "    print(f\"--- {model_name} Classification Report ---\")\n",
    "    print(classification_report(y_true, y_pred, target_names=target_names))\n",
    "\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=target_names)\n",
    "    fig, ax = plt.subplots(figsize=(8, 8))\n",
    "    disp.plot(ax=ax, cmap=plt.cm.Blues, xticks_rotation='vertical')\n",
    "    ax.set_title(f'{model_name} Confusion Matrix')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'{model_name.lower().replace(\" \", \"_\")}_confusion_matrix.png')\n",
    "    plt.close()\n",
    "    print(f\"Saved {model_name} confusion matrix as: {model_name.lower().replace(' ', '_')}_confusion_matrix.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3bdfb7c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded feature matrix with shape: (1722864, 17)\n",
      "Target 'y' classes: [0, 1, 2, 3, 4, 5, 6]\n",
      "\n",
      "Original train shape: (1378291, 12)\n",
      "Balanced train shape: (161350, 12)\n",
      "Test shape: (344573, 12)\n",
      "Classes in balanced train set: [0, 1, 2, 3, 4, 5, 6]\n",
      "\n",
      "Data preparation complete. Ready for K-Means/GMM.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# --- Define the Application Class Labels ---\n",
    "label_map = {\n",
    "    0: \"Weekday OOS Bouncers\",\n",
    "    1: \"Weekday 'Quick-Look' Visitors\",\n",
    "    2: \"Window Shoppers\",\n",
    "    3: \"Determined Buyers\",\n",
    "    4: \"Weekday OOS Bouncers (No Category)\",\n",
    "    5: \"High-Intent Shoppers\",\n",
    "    6: \"Weekend 'Quick-Look' Visitors\"\n",
    "}\n",
    "target_names = list(label_map.values())\n",
    "n_clusters = len(target_names) # 7\n",
    "\n",
    "# --- 1. Load Data ---\n",
    "# Note: Assuming this file contains the unscaled data and the 'cluster' column\n",
    "try:\n",
    "    df_features = pd.read_csv('../session_feature_matrix_with_k7_clusters.csv', index_col='session_id')\n",
    "    df_features = df_features.rename(columns={'cluster': 'label'})\n",
    "    print(f\"Loaded feature matrix with shape: {df_features.shape}\")\n",
    "except FileNotFoundError:\n",
    "    print(\"Error: 'session_feature_matrix_with_k7_clusters.csv' not found.\")\n",
    "    df_features = None\n",
    "\n",
    "if df_features is not None:\n",
    "    features_for_clustering = [\n",
    "        'session_duration_sec', 'total_events', 'unique_items_viewed',\n",
    "        'unique_categories_viewed', 'avg_item_availability',\n",
    "        'session_hour_of_day', 'view_count', 'addtocart_count',\n",
    "        'event_rate_per_sec', 'view_to_cart_ratio',\n",
    "        'category_spread_ratio', 'is_weekend'\n",
    "    ]\n",
    "\n",
    "    # --- 2. Separate Features (X) and Target (y) ---\n",
    "    X_raw = df_features[features_for_clustering].values\n",
    "    y = df_features['label'].values\n",
    "    print(f\"Target 'y' classes: {sorted(list(np.unique(y)))}\")\n",
    "\n",
    "    # --- 3. Split Data FIRST (Crucial for proper scaling) ---\n",
    "    X_train_raw, X_test_raw, y_train, y_test = train_test_split(\n",
    "        X_raw, y, test_size=0.2, stratify=y, random_state=42\n",
    "    )\n",
    "\n",
    "    # --- 4. Scale Features (Fit only on X_train_raw) ---\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train_raw)\n",
    "    X_test_scaled = scaler.transform(X_test_raw) # Transform test set using TRAIN mean/std\n",
    "\n",
    "    # --- 5. Balance the Training Data (X_train_bal, y_train_bal) ---\n",
    "    rus = RandomUnderSampler(sampling_strategy='auto', random_state=42)\n",
    "    X_train_bal, y_train_bal = rus.fit_resample(X_train_scaled, y_train)\n",
    "\n",
    "\n",
    "    print(f\"\\nOriginal train shape: {X_train_scaled.shape}\")\n",
    "    print(f\"Balanced train shape: {X_train_bal.shape}\")\n",
    "    print(f\"Test shape: {X_test_scaled.shape}\")\n",
    "    print(f\"Classes in balanced train set: {sorted(list(set(y_train_bal)))}\")\n",
    "\n",
    "    # Rename scaled variables for model input\n",
    "    X_train_bal = X_train_bal\n",
    "    X_test = X_test_scaled\n",
    "\n",
    "    print(\"\\nData preparation complete. Ready for K-Means/GMM.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "55096f42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- K-Means Transductive Mapping ---\n",
      "Cluster 0 -> Class 5 (High-Intent Shoppers)\n",
      "Cluster 1 -> Class 2 (Window Shoppers)\n",
      "Cluster 2 -> Class 4 (Weekday OOS Bouncers (No Category))\n",
      "Cluster 3 -> Class 4 (Weekday OOS Bouncers (No Category))\n",
      "Cluster 4 -> Class 4 (Weekday OOS Bouncers (No Category))\n",
      "Cluster 5 -> Class 6 (Weekend 'Quick-Look' Visitors)\n",
      "Cluster 6 -> Class 0 (Weekday OOS Bouncers)\n",
      "--- K-Means Transductive Classification Report ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Nothando\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "c:\\Users\\Nothando\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "c:\\Users\\Nothando\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                    precision    recall  f1-score   support\n",
      "\n",
      "              Weekday OOS Bouncers       1.00      1.00      1.00     40517\n",
      "     Weekday 'Quick-Look' Visitors       0.00      0.00      0.00     41972\n",
      "                   Window Shoppers       0.89      1.00      0.94     66331\n",
      "                 Determined Buyers       0.00      0.00      0.00     57043\n",
      "Weekday OOS Bouncers (No Category)       0.75      1.00      0.86      5762\n",
      "              High-Intent Shoppers       0.45      1.00      0.62     72754\n",
      "     Weekend 'Quick-Look' Visitors       0.96      0.97      0.96     60194\n",
      "\n",
      "                          accuracy                           0.71    344573\n",
      "                         macro avg       0.58      0.71      0.63    344573\n",
      "                      weighted avg       0.56      0.71      0.61    344573\n",
      "\n",
      "Saved K-Means Transductive confusion matrix as: k-means_transductive_confusion_matrix.png\n"
     ]
    }
   ],
   "source": [
    "# --- K-Means: 1. Fit Clustering on Balanced Training Data ---\n",
    "kmeans_eval = MiniBatchKMeans(\n",
    "    n_clusters=n_clusters,\n",
    "    random_state=42,\n",
    "    n_init='auto',\n",
    "    batch_size=2048\n",
    ")\n",
    "\n",
    "# Fit on the balanced training data, as per your constraint\n",
    "kmeans_eval.fit(X_train_bal)\n",
    "train_cluster_labels = kmeans_eval.labels_\n",
    "\n",
    "# --- K-Means: 2. Transductive Mapping (Majority Vote) ---\n",
    "cluster_to_class_map_km = {}\n",
    "# Ensure we use the numerical labels from the training data for mapping\n",
    "possible_classes = sorted(list(set(y_train_bal)))\n",
    "\n",
    "print(\"\\n--- K-Means Transductive Mapping ---\")\n",
    "for k in range(n_clusters):\n",
    "    # Find indices of all training points in this cluster\n",
    "    train_indices_in_cluster = np.where(train_cluster_labels == k)[0]\n",
    "\n",
    "    if len(train_indices_in_cluster) > 0:\n",
    "        cluster_true_labels = y_train_bal[train_indices_in_cluster]\n",
    "\n",
    "        # Determine the majority class (numerical label)\n",
    "        # mode returns an object, we take the first element of the array of modes\n",
    "       # Determine the majority class (numerical label) using robust bincount method\n",
    "        counts = np.bincount(cluster_true_labels)\n",
    "        # argmax returns the index of the highest count, which is the majority class label\n",
    "        majority_class_num = np.argmax(counts)\n",
    "        cluster_to_class_map_km[k] = majority_class_num\n",
    "        print(f\"Cluster {k} -> Class {majority_class_num} ({label_map[majority_class_num]})\")\n",
    "    else:\n",
    "        # Handle \"no labels\" case by choosing randomly\n",
    "        random_class_num = random.choice(possible_classes)\n",
    "        cluster_to_class_map_km[k] = random_class_num\n",
    "        print(f\"Cluster {k} -> NO LABELS. Chosen randomly: {random_class_num} ({label_map[random_class_num]})\")\n",
    "\n",
    "# --- K-Means: 3. Predict and Evaluate on Test Data ---\n",
    "# Predict the cluster ID for the test data\n",
    "test_cluster_labels = kmeans_eval.predict(X_test)\n",
    "\n",
    "# Map the cluster ID to the final application class label (numerical)\n",
    "y_pred_km = np.array([cluster_to_class_map_km[cluster_id] for cluster_id in test_cluster_labels])\n",
    "\n",
    "# Evaluate using the defined target_names\n",
    "evaluate_model(y_test, y_pred_km, \"K-Means Transductive\", target_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c7d88f41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: 'df_user_features_with_clusters.csv' not found.\n",
      "\n",
      "--- GMM Transductive Mapping ---\n",
      "Cluster 0 -> Class 3 (Determined Buyers)\n",
      "Cluster 1 -> Class 4 (Weekday OOS Bouncers (No Category))\n",
      "Cluster 2 -> Class 4 (Weekday OOS Bouncers (No Category))\n",
      "Cluster 3 -> Class 6 (Weekend 'Quick-Look' Visitors)\n",
      "Cluster 4 -> Class 2 (Window Shoppers)\n",
      "Cluster 5 -> Class 0 (Weekday OOS Bouncers)\n",
      "Cluster 6 -> Class 5 (High-Intent Shoppers)\n",
      "--- GMM Transductive Classification Report ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Nothando\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "c:\\Users\\Nothando\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "c:\\Users\\Nothando\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                    precision    recall  f1-score   support\n",
      "\n",
      "              Weekday OOS Bouncers       1.00      0.94      0.97     40517\n",
      "     Weekday 'Quick-Look' Visitors       0.00      0.00      0.00     41972\n",
      "                   Window Shoppers       0.61      0.99      0.76     66331\n",
      "                 Determined Buyers       1.00      0.97      0.99     57043\n",
      "Weekday OOS Bouncers (No Category)       0.35      1.00      0.52      5762\n",
      "              High-Intent Shoppers       1.00      0.99      0.99     72754\n",
      "     Weekend 'Quick-Look' Visitors       0.88      0.82      0.85     60194\n",
      "\n",
      "                          accuracy                           0.83    344573\n",
      "                         macro avg       0.69      0.82      0.72    344573\n",
      "                      weighted avg       0.77      0.83      0.79    344573\n",
      "\n",
      "Saved GMM Transductive confusion matrix as: gmm_transductive_confusion_matrix.png\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    # This file has the scaled features AND the original cluster label\n",
    "    df_features = pd.read_csv('df_user_features_with_clusters.csv', index_col='session_id')\n",
    "    df_features = df_features.rename(columns={'cluster_gmm': 'label'})\n",
    "    print(f\"Loaded feature matrix with shape: {df_features.shape}\")\n",
    "except FileNotFoundError:\n",
    "    print(\"Error: 'df_user_features_with_clusters.csv' not found.\")\n",
    "    df_features = None # Handle error appropriately\n",
    "\n",
    "# --- 2. Define Features (X) and MULTI-CLASS Target (y) ---\n",
    "if df_features is not None:\n",
    "    features_for_clustering = [\n",
    "        'session_duration_sec', 'total_events', 'unique_items_viewed',\n",
    "        'unique_categories_viewed', 'avg_item_availability',\n",
    "        'session_hour_of_day', 'view_count', 'addtocart_count',\n",
    "        'event_rate_per_sec', 'view_to_cart_ratio',\n",
    "        'category_spread_ratio', 'is_weekend'\n",
    "    ]\n",
    "\n",
    "    # We are using the pre-scaled data from the file\n",
    "    X = df_features[features_for_clustering].values\n",
    "\n",
    "    # *** THIS IS THE KEY CHANGE ***\n",
    "    # The target 'y' is now the multi-class 'label' (0-6)\n",
    "    y = df_features['label'].values\n",
    "    print(f\"Target 'y' classes: {sorted(list(np.unique(y)))}\")\n",
    "\n",
    "    # --- 3. Split Data FIRST (Crucial for proper scaling) ---\n",
    "    X_train_raw, X_test_raw, y_train, y_test = train_test_split(\n",
    "        X_raw, y, test_size=0.2, stratify=y, random_state=42\n",
    "    )\n",
    "\n",
    "    # --- 4. Scale Features (Fit only on X_train_raw) ---\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train_raw)\n",
    "    X_test_scaled = scaler.transform(X_test_raw) # Transform test set using TRAIN mean/std\n",
    "\n",
    "    # --- 5. Balance the Training Data (X_train_bal, y_train_bal) ---\n",
    "    rus = RandomUnderSampler(sampling_strategy='auto', random_state=42)\n",
    "    X_train_bal, y_train_bal = rus.fit_resample(X_train_scaled, y_train)\n",
    "\n",
    "    # Rename scaled variables for model input\n",
    "    X_train_bal = X_train_bal\n",
    "    X_test = X_test_scaled\n",
    "# --- GMM: 1. Fit Clustering on Balanced Training Data ---\n",
    "gmm_eval = GaussianMixture(\n",
    "    n_components=n_clusters,\n",
    "    random_state=42,\n",
    "    covariance_type='spherical',\n",
    "    n_init=10\n",
    ")\n",
    "\n",
    "# Fit on the balanced training data, as per your constraint\n",
    "gmm_eval.fit(X_train_bal)\n",
    "train_cluster_labels = gmm_eval.predict(X_train_bal)\n",
    "\n",
    "# --- GMM: 2. Transductive Mapping (Majority Vote) ---\n",
    "cluster_to_class_map_gmm = {}\n",
    "possible_classes = sorted(list(set(y_train_bal)))\n",
    "\n",
    "print(\"\\n--- GMM Transductive Mapping ---\")\n",
    "for k in range(n_clusters):\n",
    "    # Find indices of all training points in this cluster\n",
    "    train_indices_in_cluster = np.where(train_cluster_labels == k)[0]\n",
    "\n",
    "    if len(train_indices_in_cluster) > 0:\n",
    "        cluster_true_labels = y_train_bal[train_indices_in_cluster]\n",
    "\n",
    "        # Determine the majority class (numerical label)\n",
    "        # Determine the majority class (numerical label) using robust bincount method\n",
    "        counts = np.bincount(cluster_true_labels)\n",
    "        # argmax returns the index of the highest count, which is the majority class label\n",
    "        majority_class_num = np.argmax(counts)\n",
    "        cluster_to_class_map_gmm[k] = majority_class_num\n",
    "        print(f\"Cluster {k} -> Class {majority_class_num} ({label_map[majority_class_num]})\")\n",
    "    else:\n",
    "        # Handle \"no labels\" case by choosing randomly\n",
    "        random_class_num = random.choice(possible_classes)\n",
    "        cluster_to_class_map_gmm[k] = random_class_num\n",
    "        print(f\"Cluster {k} -> NO LABELS. Chosen randomly: {random_class_num} ({label_map[random_class_num]})\")\n",
    "\n",
    "# --- GMM: 3. Predict and Evaluate on Test Data ---\n",
    "# Predict the cluster ID for the test data\n",
    "test_cluster_labels = gmm_eval.predict(X_test)\n",
    "\n",
    "# Map the cluster ID to the final application class label (numerical)\n",
    "y_pred_gmm = np.array([cluster_to_class_map_gmm[cluster_id] for cluster_id in test_cluster_labels])\n",
    "\n",
    "# Evaluate using the defined target_names\n",
    "evaluate_model(y_test, y_pred_gmm, \"GMM Transductive\", target_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6a27f3d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Side-by-Side Comparison of Classification Performance (Non-Zero Recall Classes) ---\n",
      "\n",
      "F1-score/Recall Comparison:\n",
      "|                                    |   K-Means F1-score |   GMM F1-score |   K-Means Recall |   GMM Recall |   Support |\n",
      "|:-----------------------------------|-------------------:|---------------:|-----------------:|-------------:|----------:|\n",
      "| Weekday OOS Bouncers               |               1.00 |           0.97 |             1.00 |         0.94 |  40517.00 |\n",
      "| Window Shoppers                    |               0.94 |           0.76 |             1.00 |         0.99 |  66331.00 |\n",
      "| Determined Buyers                  |               0.00 |           0.99 |             0.00 |         0.97 |  57043.00 |\n",
      "| Weekday OOS Bouncers (No Category) |               0.86 |           0.52 |             1.00 |         1.00 |   5762.00 |\n",
      "| High-Intent Shoppers               |               0.62 |           0.99 |             1.00 |         0.99 |  72754.00 |\n",
      "| Weekend 'Quick-Look' Visitors      |               0.96 |           0.85 |             0.97 |         0.82 |  60194.00 |\n",
      "\n",
      "Overall Accuracy Comparison:\n",
      "| Metric           |   K-Means |   GMM |\n",
      "|:-----------------|----------:|------:|\n",
      "| Overall Accuracy |      0.71 |  0.83 |\n",
      "\n",
      "Saved F1-score comparison plot as: f1_score_comparison_km_gmm.png\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# --- SIMULATING THE CLASSIFICATION REPORTS FROM THE NOTEBOOK OUTPUT ---\n",
    "# This data is extracted directly from the output of cells [18] and [24].\n",
    "km_report = {\n",
    "    'Weekday OOS Bouncers': {'precision': 1.00, 'recall': 1.00, 'f1-score': 1.00, 'support': 40517},\n",
    "    \"Weekday 'Quick-Look' Visitors\": {'precision': 0.00, 'recall': 0.00, 'f1-score': 0.00, 'support': 41972},\n",
    "    'Window Shoppers': {'precision': 0.89, 'recall': 1.00, 'f1-score': 0.94, 'support': 66331},\n",
    "    'Determined Buyers': {'precision': 0.00, 'recall': 0.00, 'f1-score': 0.00, 'support': 57043},\n",
    "    'Weekday OOS Bouncers (No Category)': {'precision': 0.75, 'recall': 1.00, 'f1-score': 0.86, 'support': 5762},\n",
    "    'High-Intent Shoppers': {'precision': 0.45, 'recall': 1.00, 'f1-score': 0.62, 'support': 72754},\n",
    "    \"Weekend 'Quick-Look' Visitors\": {'precision': 0.96, 'recall': 0.97, 'f1-score': 0.96, 'support': 60194},\n",
    "    'accuracy': 0.71,\n",
    "    'macro avg': {'precision': 0.58, 'recall': 0.71, 'f1-score': 0.63, 'support': 344573},\n",
    "    'weighted avg': {'precision': 0.56, 'recall': 0.71, 'f1-score': 0.61, 'support': 344573}\n",
    "}\n",
    "\n",
    "gmm_report = {\n",
    "    'Weekday OOS Bouncers': {'precision': 1.00, 'recall': 0.94, 'f1-score': 0.97, 'support': 40517},\n",
    "    \"Weekday 'Quick-Look' Visitors\": {'precision': 0.00, 'recall': 0.00, 'f1-score': 0.00, 'support': 41972},\n",
    "    'Window Shoppers': {'precision': 0.61, 'recall': 0.99, 'f1-score': 0.76, 'support': 66331},\n",
    "    'Determined Buyers': {'precision': 1.00, 'recall': 0.97, 'f1-score': 0.99, 'support': 57043},\n",
    "    'Weekday OOS Bouncers (No Category)': {'precision': 0.35, 'recall': 1.00, 'f1-score': 0.52, 'support': 5762},\n",
    "    'High-Intent Shoppers': {'precision': 1.00, 'recall': 0.99, 'f1-score': 0.99, 'support': 72754},\n",
    "    \"Weekend 'Quick-Look' Visitors\": {'precision': 0.88, 'recall': 0.82, 'f1-score': 0.85, 'support': 60194},\n",
    "    'accuracy': 0.83,\n",
    "    'macro avg': {'precision': 0.69, 'recall': 0.82, 'f1-score': 0.72, 'support': 344573},\n",
    "    'weighted avg': {'precision': 0.77, 'recall': 0.83, 'f1-score': 0.79, 'support': 344573}\n",
    "}\n",
    "\n",
    "# Get class names\n",
    "target_names = list(km_report.keys())[:-3]\n",
    "\n",
    "# 1. Convert reports to DataFrames\n",
    "km_df = pd.DataFrame(km_report).transpose()\n",
    "gmm_df = pd.DataFrame(gmm_report).transpose()\n",
    "\n",
    "# 2. Filter for only the classification classes\n",
    "km_class_df = km_df.loc[target_names].copy()\n",
    "gmm_class_df = gmm_df.loc[target_names].copy()\n",
    "\n",
    "# 3. Filter for non-zero recall classes in AT LEAST ONE model\n",
    "km_recall = km_class_df['recall']\n",
    "gmm_recall = gmm_class_df['recall']\n",
    "non_zero_recall_mask = (km_recall > 0.00) | (gmm_recall > 0.00)\n",
    "\n",
    "km_filtered = km_class_df[non_zero_recall_mask][['precision', 'recall', 'f1-score', 'support']]\n",
    "gmm_filtered = gmm_class_df[non_zero_recall_mask][['precision', 'recall', 'f1-score', 'support']]\n",
    "\n",
    "# 4. Create the side-by-side comparison DataFrame\n",
    "comparison_df = pd.DataFrame({\n",
    "    'K-Means F1-score': km_filtered['f1-score'],\n",
    "    'GMM F1-score': gmm_filtered['f1-score'],\n",
    "    'K-Means Recall': km_filtered['recall'],\n",
    "    'GMM Recall': gmm_filtered['recall'],\n",
    "    'Support': km_filtered['support'].astype(int)\n",
    "})\n",
    "\n",
    "# Add overall accuracy for a full picture\n",
    "overall_accuracy = pd.DataFrame({\n",
    "    'Metric': ['Overall Accuracy'],\n",
    "    'K-Means': [km_report['accuracy']],\n",
    "    'GMM': [gmm_report['accuracy']]\n",
    "}).set_index('Metric')\n",
    "\n",
    "print(\"--- Side-by-Side Comparison of Classification Performance (Non-Zero Recall Classes) ---\")\n",
    "print(\"\\nF1-score/Recall Comparison:\")\n",
    "print(comparison_df.to_markdown(floatfmt=\".2f\"))\n",
    "\n",
    "print(\"\\nOverall Accuracy Comparison:\")\n",
    "print(overall_accuracy.to_markdown(floatfmt=\".2f\"))\n",
    "\n",
    "# --- Draw a Bar Chart for F1-score comparison ---\n",
    "plot_df = comparison_df[['K-Means F1-score', 'GMM F1-score']].reset_index()\n",
    "plot_df = plot_df.rename(columns={'index': 'Class'})\n",
    "plot_melted = plot_df.melt('Class', var_name='Model', value_name='F1-score')\n",
    "\n",
    "plt.figure(figsize=(12, 7))\n",
    "sns.barplot(x='Class', y='F1-score', hue='Model', data=plot_melted, palette=['skyblue', 'salmon'])\n",
    "plt.title('F1-Score Comparison for Non-Zero Recall Classes: K-Means vs. GMM')\n",
    "plt.ylabel('F1-score')\n",
    "plt.xlabel('Customer Segment')\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.ylim(0, 1.05)\n",
    "plt.legend(title='Model')\n",
    "plt.tight_layout()\n",
    "plt.savefig('f1_score_comparison_km_gmm.png')\n",
    "plt.close()\n",
    "print(\"\\nSaved F1-score comparison plot as: f1_score_comparison_km_gmm.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9aa79fd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# --- SIMULATING THE CLASSIFICATION REPORTS FROM THE NOTEBOOK OUTPUT ---\n",
    "# This data is necessary to reconstruct the comparison DataFrame for plotting.\n",
    "km_report = {\n",
    "    'Weekday OOS Bouncers': {'precision': 1.00, 'recall': 1.00, 'f1-score': 1.00, 'support': 40517},\n",
    "    \"Weekday 'Quick-Look' Visitors\": {'precision': 0.00, 'recall': 0.00, 'f1-score': 0.00, 'support': 41972},\n",
    "    'Window Shoppers': {'precision': 0.89, 'recall': 1.00, 'f1-score': 0.94, 'support': 66331},\n",
    "    'Determined Buyers': {'precision': 0.00, 'recall': 0.00, 'f1-score': 0.00, 'support': 57043},\n",
    "    'Weekday OOS Bouncers (No Category)': {'precision': 0.75, 'recall': 1.00, 'f1-score': 0.86, 'support': 5762},\n",
    "    'High-Intent Shoppers': {'precision': 0.45, 'recall': 1.00, 'f1-score': 0.62, 'support': 72754},\n",
    "    \"Weekend 'Quick-Look' Visitors\": {'precision': 0.96, 'recall': 0.97, 'f1-score': 0.96, 'support': 60194},\n",
    "}\n",
    "\n",
    "gmm_report = {\n",
    "    'Weekday OOS Bouncers': {'precision': 1.00, 'recall': 0.94, 'f1-score': 0.97, 'support': 40517},\n",
    "    \"Weekday 'Quick-Look' Visitors\": {'precision': 0.00, 'recall': 0.00, 'f1-score': 0.00, 'support': 41972},\n",
    "    'Window Shoppers': {'precision': 0.61, 'recall': 0.99, 'f1-score': 0.76, 'support': 66331},\n",
    "    'Determined Buyers': {'precision': 1.00, 'recall': 0.97, 'f1-score': 0.99, 'support': 57043},\n",
    "    'Weekday OOS Bouncers (No Category)': {'precision': 0.35, 'recall': 1.00, 'f1-score': 0.52, 'support': 5762},\n",
    "    'High-Intent Shoppers': {'precision': 1.00, 'recall': 0.99, 'f1-score': 0.99, 'support': 72754},\n",
    "    \"Weekend 'Quick-Look' Visitors\": {'precision': 0.88, 'recall': 0.82, 'f1-score': 0.85, 'support': 60194},\n",
    "}\n",
    "\n",
    "target_names = list(km_report.keys())\n",
    "\n",
    "# 1. Convert reports to DataFrames and combine F1-scores\n",
    "km_class_df = pd.DataFrame(km_report).transpose().loc[target_names].copy()\n",
    "gmm_class_df = pd.DataFrame(gmm_report).transpose().loc[target_names].copy()\n",
    "\n",
    "# 2. Filter for non-zero recall classes in AT LEAST ONE model\n",
    "non_zero_recall_mask = (km_class_df['recall'] > 0.00) | (gmm_class_df['recall'] > 0.00)\n",
    "\n",
    "comparison_df = pd.DataFrame({\n",
    "    'K-Means F1-score': km_class_df[non_zero_recall_mask]['f1-score'],\n",
    "    'GMM F1-score': gmm_class_df[non_zero_recall_mask]['f1-score'],\n",
    "})\n",
    "\n",
    "# 3. Prepare data for plotting F1-scores\n",
    "plot_df = comparison_df[['K-Means F1-score', 'GMM F1-score']].reset_index()\n",
    "plot_df = plot_df.rename(columns={'index': 'Class'})\n",
    "\n",
    "# Melt the DataFrame to long format, suitable for grouped bar chart plotting\n",
    "plot_melted = plot_df.melt('Class', var_name='Model', value_name='F1-score')\n",
    "\n",
    "# --- Plotting Code ---\n",
    "plt.figure(figsize=(12, 7))\n",
    "sns.barplot(x='Class', y='F1-score', hue='Model', data=plot_melted, palette=['skyblue', 'salmon'])\n",
    "plt.title('F1-Score Comparison for Non-Zero Recall Classes: K-Means vs. GMM')\n",
    "plt.ylabel('F1-score')\n",
    "plt.xlabel('Customer Segment')\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.ylim(0, 1.05)\n",
    "plt.legend(title='Model')\n",
    "plt.tight_layout()\n",
    "plt.savefig('f1_score_comparison_km_gmm.png')\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "295edd86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: mlxtend in c:\\users\\nothando\\anaconda3\\lib\\site-packages (0.23.4)\n",
      "Requirement already satisfied: scipy>=1.2.1 in c:\\users\\nothando\\anaconda3\\lib\\site-packages (from mlxtend) (1.11.4)\n",
      "Requirement already satisfied: numpy>=1.16.2 in c:\\users\\nothando\\anaconda3\\lib\\site-packages (from mlxtend) (1.26.4)\n",
      "Requirement already satisfied: pandas>=0.24.2 in c:\\users\\nothando\\anaconda3\\lib\\site-packages (from mlxtend) (2.1.4)\n",
      "Requirement already satisfied: scikit-learn>=1.3.1 in c:\\users\\nothando\\anaconda3\\lib\\site-packages (from mlxtend) (1.7.2)\n",
      "Requirement already satisfied: matplotlib>=3.0.0 in c:\\users\\nothando\\anaconda3\\lib\\site-packages (from mlxtend) (3.8.0)\n",
      "Requirement already satisfied: joblib>=0.13.2 in c:\\users\\nothando\\anaconda3\\lib\\site-packages (from mlxtend) (1.2.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\nothando\\anaconda3\\lib\\site-packages (from matplotlib>=3.0.0->mlxtend) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\nothando\\anaconda3\\lib\\site-packages (from matplotlib>=3.0.0->mlxtend) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\nothando\\anaconda3\\lib\\site-packages (from matplotlib>=3.0.0->mlxtend) (4.25.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\nothando\\anaconda3\\lib\\site-packages (from matplotlib>=3.0.0->mlxtend) (1.4.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\nothando\\anaconda3\\lib\\site-packages (from matplotlib>=3.0.0->mlxtend) (23.1)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\nothando\\anaconda3\\lib\\site-packages (from matplotlib>=3.0.0->mlxtend) (10.2.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\nothando\\anaconda3\\lib\\site-packages (from matplotlib>=3.0.0->mlxtend) (3.0.9)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\nothando\\anaconda3\\lib\\site-packages (from matplotlib>=3.0.0->mlxtend) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\nothando\\anaconda3\\lib\\site-packages (from pandas>=0.24.2->mlxtend) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\users\\nothando\\anaconda3\\lib\\site-packages (from pandas>=0.24.2->mlxtend) (2023.3)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\nothando\\anaconda3\\lib\\site-packages (from scikit-learn>=1.3.1->mlxtend) (3.6.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\nothando\\anaconda3\\lib\\site-packages (from python-dateutil>=2.7->matplotlib>=3.0.0->mlxtend) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install mlxtend"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5311c965",
   "metadata": {},
   "source": [
    "### Associative Rule Classification Unit\n",
    "\n",
    "Association Rule Classification unit provides finer classification to the model. Association rules find regularities between flow parameters with different measures of interestingness for applications from transductive classifier output. The Apriori Algorithm is used for association rule learning. The derived rules are traced back to the main dataset and identified flows. Moreover, the rule association also helps predict IPs and ports used for servicing an application in the future. The rules heuristics applied to flow data causes accurate classification and thus making classification method finer due to association rule mining techniques."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7db2b591",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Step 1: Data Discretization and Conversion for Apriori ---\n",
      "Warning: Could not qcut session_duration_sec. Using simple cut instead. Error: Bin labels must be one fewer than the number of bin edges\n",
      "Warning: Could not qcut total_events. Using simple cut instead. Error: Bin labels must be one fewer than the number of bin edges\n",
      "Warning: Could not qcut unique_items_viewed. Using simple cut instead. Error: Bin labels must be one fewer than the number of bin edges\n",
      "Warning: Could not qcut unique_categories_viewed. Using simple cut instead. Error: Bin labels must be one fewer than the number of bin edges\n",
      "Warning: Could not qcut avg_item_availability. Using simple cut instead. Error: Bin labels must be one fewer than the number of bin edges\n",
      "Warning: Could not qcut view_count. Using simple cut instead. Error: Bin labels must be one fewer than the number of bin edges\n",
      "Warning: Could not qcut addtocart_count. Using simple cut instead. Error: Bin labels must be one fewer than the number of bin edges\n",
      "Warning: Could not qcut event_rate_per_sec. Using simple cut instead. Error: Bin labels must be one fewer than the number of bin edges\n",
      "Warning: Could not qcut view_to_cart_ratio. Using simple cut instead. Error: Bin labels must be one fewer than the number of bin edges\n",
      "Warning: Could not qcut category_spread_ratio. Using simple cut instead. Error: Bin labels must be one fewer than the number of bin edges\n",
      "One-Hot Encoded DataFrame shape for Apriori: (161350, 40)\n"
     ]
    }
   ],
   "source": [
    "# New Code Cell (e.g., cell 28)\n",
    "import pandas as pd\n",
    "from mlxtend.frequent_patterns import apriori\n",
    "from mlxtend.frequent_patterns import association_rules\n",
    "\n",
    "print(\"--- Step 1: Data Discretization and Conversion for Apriori ---\")\n",
    "\n",
    "# Combine scaled features (X_train_bal) with the class label (y_train_bal)\n",
    "# Reconstruct a DataFrame for easier handling\n",
    "feature_names = [\n",
    "    'session_duration_sec', 'total_events', 'unique_items_viewed',\n",
    "    'unique_categories_viewed', 'avg_item_availability',\n",
    "    'session_hour_of_day', 'view_count', 'addtocart_count',\n",
    "    'event_rate_per_sec', 'view_to_cart_ratio',\n",
    "    'category_spread_ratio', 'is_weekend'\n",
    "]\n",
    "df_train_bal = pd.DataFrame(X_train_bal, columns=feature_names)\n",
    "df_train_bal['target_class'] = y_train_bal\n",
    "\n",
    "# --- Discretization (Binning) ---\n",
    "# This is a crucial step for continuous data in ARM.\n",
    "# We'll use a simple quantile-based binning (qcut) for most features.\n",
    "\n",
    "discretized_features = {}\n",
    "for col in features_for_clustering:\n",
    "    # Skip 'is_weekend' as it's already binary (0 or 1)\n",
    "    if col == 'is_weekend':\n",
    "        df_train_bal[f'{col}_Binned'] = df_train_bal[col].astype(bool)\n",
    "        continue\n",
    "\n",
    "    # Use 3 bins for continuous features: Low, Medium, High\n",
    "    try:\n",
    "        # Create bins based on quantiles (equal frequency)\n",
    "        df_train_bal[f'{col}_Binned'] = pd.qcut(\n",
    "            df_train_bal[col], q=3, labels=['Low', 'Medium', 'High'], duplicates='drop'\n",
    "        ).astype(str)\n",
    "    except ValueError as e:\n",
    "        # Handle cases where a feature might have too few unique values for 3 quantiles\n",
    "        print(f\"Warning: Could not qcut {col}. Using simple cut instead. Error: {e}\")\n",
    "        df_train_bal[f'{col}_Binned'] = pd.cut(\n",
    "            df_train_bal[col], bins=3, labels=['Low', 'Medium', 'High'], include_lowest=True\n",
    "        ).astype(str)\n",
    "\n",
    "    discretized_features[col] = f'{col}_Binned'\n",
    "\n",
    "# Convert the numerical 'target_class' back to its descriptive name for clear rules\n",
    "class_names = [label_map[i] for i in df_train_bal['target_class']]\n",
    "df_train_bal['Target_Class_Name'] = class_names\n",
    "\n",
    "# Select only the binned columns and the target\n",
    "binned_cols = list(discretized_features.values()) + ['Target_Class_Name']\n",
    "df_apriori = df_train_bal[binned_cols]\n",
    "\n",
    "# --- One-Hot Encoding (for Apriori input) ---\n",
    "# Create an itemset for each row. Prefix all feature columns for clarity.\n",
    "df_one_hot = pd.get_dummies(df_apriori, columns=df_apriori.columns, prefix=df_apriori.columns, dtype=bool)\n",
    "\n",
    "# Drop redundant/unwanted columns (like the original binned columns' name)\n",
    "df_one_hot.columns = [c.replace('_Binned_', '_') for c in df_one_hot.columns]\n",
    "df_one_hot.columns = [c.replace('_Target_Class_Name_', 'CLASS_') for c in df_one_hot.columns]\n",
    "\n",
    "print(f\"One-Hot Encoded DataFrame shape for Apriori: {df_one_hot.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ed8002a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# New Code Cell (e.g., cell 29)\n",
    "\n",
    "# --- Apriori Algorithm ---\n",
    "# Find frequent itemsets (min_support is a hyperparameter to tune)\n",
    "min_support = 0.05\n",
    "frequent_itemsets = apriori(df_one_hot, min_support=min_support, use_colnames=True)\n",
    "print(f\"\\nFound {len(frequent_itemsets)} frequent itemsets with min_support={min_support}\")\n",
    "\n",
    "# --- Association Rule Generation ---\n",
    "# Generate rules (min_confidence is a hyperparameter to tune)\n",
    "# Lift is a key measure of interestingness (Lift > 1 suggests a positive association)\n",
    "min_confidence = 0.8\n",
    "rules = association_rules(frequent_itemsets, metric=\"confidence\", min_threshold=min_confidence)\n",
    "\n",
    "# Filter rules to only include those that predict a CLASS (i.e., classification rules)\n",
    "classification_rules = rules[rules['consequents'].apply(lambda x: any('CLASS_' in item for item in x))]\n",
    "\n",
    "# Filter for the most interesting rules (high lift, high confidence)\n",
    "classification_rules_sorted = classification_rules.sort_values(\n",
    "    by=['lift', 'confidence'], ascending=False\n",
    ").reset_index(drop=True)\n",
    "\n",
    "# Select and display the top 10 most interesting rules\n",
    "print(f\"\\nGenerated {len(classification_rules)} classification rules with min_confidence={min_confidence}\")\n",
    "print(\"\\n--- Top 10 Associative Classification Rules (Sorted by Lift) ---\")\n",
    "\n",
    "# Formatting output for better readability\n",
    "def format_rule(row):\n",
    "    antecedent = ', '.join(list(row['antecedents']))\n",
    "    consequent = ', '.join(list(row['consequents']))\n",
    "    return (\n",
    "        f\"Rule: IF ({antecedent}) THEN ({consequent}) | \"\n",
    "        f\"Conf: {row['confidence']:.2f}, Lift: {row['lift']:.2f}, \"\n",
    "        f\"Support: {row['support']:.3f}\"\n",
    "    )\n",
    "\n",
    "for i, row in classification_rules_sorted.head(10).iterrows():\n",
    "    print(format_rule(row))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a75b8e41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# New Code Cell (e.g., cell 30)\n",
    "# --- Conceptual Associative Rule Classifier (Max Confidence Heuristic) ---\n",
    "\n",
    "# This code is highly simplified and requires careful mapping of test data\n",
    "# to the one-hot format. This cell is for demonstration only.\n",
    "\n",
    "print(\"\\n--- Associative Rule Classification Unit Heuristic (Max Confidence) ---\")\n",
    "\n",
    "# Step 1: Prepare a simplified set of rules for the classifier.\n",
    "# We'll use only the antecedents, the predicted class, and confidence.\n",
    "rule_list = []\n",
    "for index, row in classification_rules_sorted.iterrows():\n",
    "    # Only keep single-class consequents for simplicity in this example\n",
    "    if len(row['consequents']) == 1:\n",
    "        rule_list.append({\n",
    "            'antecedents': set(row['antecedents']),\n",
    "            'consequent': list(row['consequents'])[0].replace('CLASS_', ''),\n",
    "            'confidence': row['confidence']\n",
    "        })\n",
    "\n",
    "# Step 2: Implement the classifier function (Requires *full* test data prep first)\n",
    "def predict_with_rules(test_instance_itemset, rules):\n",
    "    \"\"\"\n",
    "    Simulates prediction using the max confidence rule heuristic.\n",
    "    \"\"\"\n",
    "    matching_rules = []\n",
    "    \n",
    "    # 1. Match: Find all rules whose antecedents are a subset of the instance's itemset\n",
    "    for rule in rules:\n",
    "        if rule['antecedents'].issubset(test_instance_itemset):\n",
    "            matching_rules.append(rule)\n",
    "            \n",
    "    if not matching_rules:\n",
    "        return None # No rule matched (fallback to a default class in a real system)\n",
    "        \n",
    "    # 2. Conflict Resolution: Max Confidence\n",
    "    best_rule = max(matching_rules, key=lambda x: x['confidence'])\n",
    "    \n",
    "    return best_rule['consequent']\n",
    "\n",
    "print(\"Associative Rule Classifier logic defined. The actual prediction on X_test would require:\")\n",
    "print(\"1. Re-running the discretization on the **test set** X_test_raw with the **training set bins**.\")\n",
    "print(\"2. Converting the test set to the same one-hot itemset format.\")\n",
    "print(\"3. Iterating through the test set and applying the `predict_with_rules` function.\")\n",
    "print(\"\\nThis creates the 'finer classification' by applying specific IF-THEN conditions derived from the data.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
