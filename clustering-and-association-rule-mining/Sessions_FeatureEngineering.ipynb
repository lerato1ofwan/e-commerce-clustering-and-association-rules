{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "_pCtkLFbddYv"
      },
      "outputs": [],
      "source": [
        "from pathlib import Path\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aGIL2sVDeUF3"
      },
      "outputs": [],
      "source": [
        "BASE_DIR = '..'\n",
        "OUTPUTS_DIR = '../outputs'\n",
        "df_events = pd.read_csv(f'{BASE_DIR}/dataset/events.csv')\n",
        "df_categories = pd.read_csv(f'{BASE_DIR}/dataset/category_tree.csv')\n",
        "df_properties = pd.concat([pd.read_csv(f'{BASE_DIR}/dataset/item_properties_part1.csv'), pd.read_csv(f'{BASE_DIR}/dataset/item_properties_part2.csv')])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hs7biAQjfMP2",
        "outputId": "470e3387-d97e-4dd5-baa3-71f1e2568859"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "# Missing Values in df_events\n",
            "                 Count  Percentage\n",
            "transactionid  2733644    99.18519\n",
            "\n",
            "\n",
            "# Missing Values in df_properties\n",
            "Empty DataFrame\n",
            "Columns: [Count, Percentage]\n",
            "Index: []\n",
            "\n",
            "\n",
            "# Missing Values in df_categories\n",
            "          Count  Percentage\n",
            "parentid     25    1.497903\n",
            "\n",
            "\n",
            "# Unique Counts in df_events\n",
            "Number of unique visitors: 1,407,580\n",
            "Number of unique items involved in events: 235,061\n",
            "Number of unique transactions: 17,672\n"
          ]
        }
      ],
      "source": [
        "def missing_values_summary(df, df_name):\n",
        "    \"\"\"Calculates and prints the missing values count and percentage for a DataFrame.\"\"\"\n",
        "    print(f\"# Missing Values in {df_name}\")\n",
        "    missing_count = df.isnull().sum()\n",
        "    missing_percentage = (missing_count / len(df)) * 100\n",
        "    missing_df = pd.DataFrame({'Count': missing_count, 'Percentage': missing_percentage})\n",
        "    print(missing_df[missing_df['Count'] > 0])\n",
        "    print(\"\\n\")\n",
        "\n",
        "missing_values_summary(df_events, 'df_events')\n",
        "missing_values_summary(df_properties, 'df_properties')\n",
        "missing_values_summary(df_categories, 'df_categories')\n",
        "\n",
        "unique_visitors = df_events['visitorid'].nunique()\n",
        "unique_items = df_events['itemid'].nunique()\n",
        "unique_transactions = df_events['transactionid'].nunique()\n",
        "\n",
        "print(\"# Unique Counts in df_events\")\n",
        "print(f\"Number of unique visitors: {unique_visitors:,}\")\n",
        "print(f\"Number of unique items involved in events: {unique_items:,}\")\n",
        "print(f\"Number of unique transactions: {unique_transactions:,}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Grb-ps2NhX47"
      },
      "source": [
        "### Handling missing values\n",
        "\n",
        "Our primary goal in this preprocessing step is not to simply drop missing data, but to understand why it's missing and handle it intelligently to preserve our valuable behavioral data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9GfvJfcmhMyU",
        "outputId": "5dfaefa1-afa8-4bf6-9f4b-7f5d2d6b8aed"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Starting missing value handling...\n",
            "Processed 'df_events'. 'transactionid' NaNs filled with 0.\n",
            "Row count remains 2756101 (no rows dropped).\n",
            "\n",
            "Processed 'df_properties'. No missing values found.\n",
            "\n",
            "Processed 'df_categories'. 'parentid' NaNs filled with 0 to represent root categories.\n",
            "Row count remains 1669 (no rows dropped).\n",
            "\n",
            "Missing value handling complete.\n"
          ]
        }
      ],
      "source": [
        "print(\"Starting missing value handling...\")\n",
        "\n",
        "# 1. Handling df_events\n",
        "# EDA showed 99.18% of 'transactionid' are NaN.\n",
        "# This is expected. The 'transactionid' field is ONLY populated for the 'transaction' event type.\n",
        "# The 99% of missing values represent all the 'view' and 'addtocart' events.\n",
        "#\n",
        "# We MUST NOT drop these rows. Dropping them would remove all our behavioral data\n",
        "# for non-buying sessions, making it impossible to perform our behavioral clustering.\n",
        "#\n",
        "# We will fill the NaN values with 0. This makes the column a clean integer type,\n",
        "# which is easier for processing, and clearly separates non-transaction events (0) from\n",
        "# actual transaction events (which have a positive ID).\n",
        "original_event_count = len(df_events)\n",
        "df_events['transactionid'] = df_events['transactionid'].fillna(0).astype(int)\n",
        "print(f\"Processed 'df_events'. 'transactionid' NaNs filled with 0.\")\n",
        "print(f\"Row count remains {len(df_events)} (no rows dropped).\")\n",
        "\n",
        "# 2. Handling df_properties\n",
        "# EDA showed 0 missing values.\n",
        "# The data is clean.\n",
        "# No action required.\n",
        "print(\"\\nProcessed 'df_properties'. No missing values found.\")\n",
        "\n",
        "# 3. Handling df_categories\n",
        "# EDA showed 25 missing values for 'parentid'.\n",
        "# This is also expected. These 25 rows are the \"root\" categories\n",
        "# (e.g., \"Electronics\"). They do not have a parent, so the field is correctly left blank.\n",
        "#\n",
        "# We MUST NOT drop these rows, as that would break our category hierarchy.\n",
        "#\n",
        "# We will fill these NaNs with 0 to signify\n",
        "# they are the top-level root nodes. This maintains the integrity of the tree structure.\n",
        "original_category_count = len(df_categories)\n",
        "df_categories['parentid'] = df_categories['parentid'].fillna(0).astype(int)\n",
        "print(f\"\\nProcessed 'df_categories'. 'parentid' NaNs filled with 0 to represent root categories.\")\n",
        "print(f\"Row count remains {len(df_categories)} (no rows dropped).\")\n",
        "\n",
        "print(\"\\nMissing value handling complete.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7QyuvSj_k11R"
      },
      "source": [
        "### Noise Handling\n",
        "\n",
        "1. Statistical Noise (Outliers): We saw sessions with 7,000+ events and 50% of visitors with only 1 event. These extremes can pull the cluster centers.\n",
        "\n",
        "2. Methodological Noise (Irrelevant Data): Sessions without a 'transaction' are essential data for clustering.\n",
        "\n",
        "**Our Strategy**: We must remove these statistical outliers before we do anything else (like sessionization) because they will severely skew the feature calculations for our K-Means clustering."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rk5yJvOumi-W",
        "outputId": "26f3c742-7a3b-4b69-ea3d-d625a3076da3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Original df_events shape: (2756101, 5)\n",
            "Calculating events per visitor...\n",
            "Outlier threshold (99.9th percentile) = 47.0 events\n",
            "Found 1352 outlier visitors.\n",
            "\n",
            "# Noise Handling Summary\n",
            "Original total events: 2,756,101\n",
            "Cleaned total events: 2,536,174\n",
            "Removed 219,927 events (7.98%) belonging to 1352 visitors.\n",
            "Cleaned df_events_cleaned shape: (2536174, 5)\n"
          ]
        }
      ],
      "source": [
        "# Step 1: Noise Handling (Statistical Outliers)\n",
        "\n",
        "print(f\"Original df_events shape: {df_events.shape}\")\n",
        "\n",
        "# 1. Identify Outlier Visitors\n",
        "print(\"Calculating events per visitor...\")\n",
        "events_per_visitor = df_events.groupby('visitorid')['event'].count()\n",
        "\n",
        "# The EDA showed a massive skew. We'll define 'noise' as the extreme outliers.\n",
        "# We can find this threshold programmatically by using a\n",
        "# high quantile. Let's use the 99.9th percentile as our cutoff.\n",
        "outlier_threshold = events_per_visitor.quantile(0.999)\n",
        "print(f\"Outlier threshold (99.9th percentile) = {outlier_threshold} events\")\n",
        "\n",
        "# Get the list of visitorids that are above this threshold\n",
        "outlier_visitors = events_per_visitor[events_per_visitor > outlier_threshold].index\n",
        "print(f\"Found {len(outlier_visitors)} outlier visitors.\")\n",
        "\n",
        "\n",
        "# 2. Filter Outlier Events\n",
        "\n",
        "# Now, we remove all events associated with these outlier\n",
        "# visitors from our main df_events dataframe. This ensures they\n",
        "# won't impact our sessionization or feature engineering.\n",
        "df_events_cleaned = df_events[~df_events['visitorid'].isin(outlier_visitors)].copy()\n",
        "\n",
        "\n",
        "# 3. Report Results\n",
        "original_events = len(df_events)\n",
        "cleaned_events = len(df_events_cleaned)\n",
        "events_removed = original_events - cleaned_events\n",
        "percent_removed = (events_removed / original_events) * 100\n",
        "\n",
        "print(\"\\n# Noise Handling Summary\")\n",
        "print(f\"Original total events: {original_events:,}\")\n",
        "print(f\"Cleaned total events: {cleaned_events:,}\")\n",
        "print(f\"Removed {events_removed:,} events ({percent_removed:.2f}%) belonging to {len(outlier_visitors)} visitors.\")\n",
        "print(f\"Cleaned df_events_cleaned shape: {df_events_cleaned.shape}\")\n",
        "\n",
        "#  This cleaned dataframe is what we'll use for the next step.\n",
        "# We'll re-assign df_events to this cleaned version for the rest of the pipeline.\n",
        "df_events = df_events_cleaned"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QgaLf1Inolfn"
      },
      "source": [
        "#### Summary\n",
        "\n",
        "- We chose Removal/Filtering because the data identified as \"noise\" was not just \"extreme\" data; it was anomalous data.\n",
        "  - Based on the EDAs, the median visitor had only 1 event, while the top 0.1% had over 32, with a max of 7,757.\n",
        "- Why we removed them instead of using other methods:\n",
        "  - They Aren't \"Extreme Users,\" They're \"Non-Users.\" A visitor with thousands of events is almost certainly a bot, scraper, or internal test account. This isn't just an \"enthusiastic shopper\"; it's a different category of user entirely. Our goal is to cluster real customer behavior, so these non-human actors must be removed.\n",
        "- Why Other Methods Don't Fit:\n",
        "  - Winsorizing (Capping): This technique is for limiting the influence of a single feature (e.g., capping a session duration at 3 hours). It doesn't make sense for a user. We can't \"cap\" a bot's behavior to make it look like a humanâ€”its entire pattern is wrong.\n",
        "  - Imputation/Replacement: These methods are for missing data, not bad data. We have no value to \"impute\" here.\n",
        "  - Data Smoothing: This is typically for time-series data to reduce signal jitter, which doesn't apply to our task of identifying outlier visitors.\n",
        "-In short: These visitors are removed because they are not part of the population we want to analyze. Their behavior is statistical \"noise\" that would contaminate our clusters, pulling the cluster centers away from the real, typical user groups we are trying to find."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LmVLouDHpTI7"
      },
      "source": [
        "## Making visitor sessions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 606
        },
        "id": "9NQztwh_oHfp",
        "outputId": "46c99bee-1ff8-448a-dfea-45e0380cdc6b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Starting sessionization on 2,756,101 events...\n",
            "Converting timestamp from int (milliseconds) to datetime...\n",
            "Sorting events by visitorid and timestamp...\n",
            "Calculating time difference between events for each visitor...\n",
            "Assigning unique session IDs...\n",
            "\n",
            "Sessionization Summary\n",
            "Total events processed: 2,756,101\n",
            "Total unique visitors: 1,407,580\n",
            "Total unique sessions created: 1,761,675\n",
            "Average sessions per visitor: 1.25\n",
            "Average events per session: 1.56\n",
            "\n",
            "Sample of sessionized data (showing new session flags):\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>timestamp_dt</th>\n",
              "      <th>visitorid</th>\n",
              "      <th>event</th>\n",
              "      <th>time_diff_seconds</th>\n",
              "      <th>new_session_flag</th>\n",
              "      <th>session_id</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1361687</th>\n",
              "      <td>2015-09-11 20:49:49.439</td>\n",
              "      <td>0</td>\n",
              "      <td>view</td>\n",
              "      <td>NaN</td>\n",
              "      <td>True</td>\n",
              "      <td>0_1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1367212</th>\n",
              "      <td>2015-09-11 20:52:39.591</td>\n",
              "      <td>0</td>\n",
              "      <td>view</td>\n",
              "      <td>170.152</td>\n",
              "      <td>False</td>\n",
              "      <td>0_1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1367342</th>\n",
              "      <td>2015-09-11 20:55:17.175</td>\n",
              "      <td>0</td>\n",
              "      <td>view</td>\n",
              "      <td>157.584</td>\n",
              "      <td>False</td>\n",
              "      <td>0_1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>830385</th>\n",
              "      <td>2015-08-13 17:46:06.444</td>\n",
              "      <td>1</td>\n",
              "      <td>view</td>\n",
              "      <td>NaN</td>\n",
              "      <td>True</td>\n",
              "      <td>1_1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>742616</th>\n",
              "      <td>2015-08-07 17:51:44.567</td>\n",
              "      <td>2</td>\n",
              "      <td>view</td>\n",
              "      <td>NaN</td>\n",
              "      <td>True</td>\n",
              "      <td>2_1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>735273</th>\n",
              "      <td>2015-08-07 17:53:33.790</td>\n",
              "      <td>2</td>\n",
              "      <td>view</td>\n",
              "      <td>109.223</td>\n",
              "      <td>False</td>\n",
              "      <td>2_1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>737711</th>\n",
              "      <td>2015-08-07 17:56:52.664</td>\n",
              "      <td>2</td>\n",
              "      <td>view</td>\n",
              "      <td>198.874</td>\n",
              "      <td>False</td>\n",
              "      <td>2_1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>726292</th>\n",
              "      <td>2015-08-07 18:01:08.920</td>\n",
              "      <td>2</td>\n",
              "      <td>view</td>\n",
              "      <td>256.256</td>\n",
              "      <td>False</td>\n",
              "      <td>2_1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>737615</th>\n",
              "      <td>2015-08-07 18:08:25.669</td>\n",
              "      <td>2</td>\n",
              "      <td>view</td>\n",
              "      <td>436.749</td>\n",
              "      <td>False</td>\n",
              "      <td>2_1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>735202</th>\n",
              "      <td>2015-08-07 18:17:24.375</td>\n",
              "      <td>2</td>\n",
              "      <td>view</td>\n",
              "      <td>538.706</td>\n",
              "      <td>False</td>\n",
              "      <td>2_1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                   timestamp_dt  visitorid event  time_diff_seconds  \\\n",
              "1361687 2015-09-11 20:49:49.439          0  view                NaN   \n",
              "1367212 2015-09-11 20:52:39.591          0  view            170.152   \n",
              "1367342 2015-09-11 20:55:17.175          0  view            157.584   \n",
              "830385  2015-08-13 17:46:06.444          1  view                NaN   \n",
              "742616  2015-08-07 17:51:44.567          2  view                NaN   \n",
              "735273  2015-08-07 17:53:33.790          2  view            109.223   \n",
              "737711  2015-08-07 17:56:52.664          2  view            198.874   \n",
              "726292  2015-08-07 18:01:08.920          2  view            256.256   \n",
              "737615  2015-08-07 18:08:25.669          2  view            436.749   \n",
              "735202  2015-08-07 18:17:24.375          2  view            538.706   \n",
              "\n",
              "         new_session_flag session_id  \n",
              "1361687              True        0_1  \n",
              "1367212             False        0_1  \n",
              "1367342             False        0_1  \n",
              "830385               True        1_1  \n",
              "742616               True        2_1  \n",
              "735273              False        2_1  \n",
              "737711              False        2_1  \n",
              "726292              False        2_1  \n",
              "737615              False        2_1  \n",
              "735202              False        2_1  "
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "print(f\"Starting sessionization on {len(df_events):,} events...\")\n",
        "\n",
        "# 1. Convert Timestamp\n",
        "# To calculate time differences, we must ensure the 'timestamp'\n",
        "# column is in datetime format.\n",
        "if not pd.api.types.is_datetime64_any_dtype(df_events['timestamp']):\n",
        "    print(\"Converting timestamp from int (milliseconds) to datetime...\")\n",
        "    df_events['timestamp_dt'] = pd.to_datetime(df_events['timestamp'], unit='ms')\n",
        "else:\n",
        "    # Handle case where it might have been converted in a notebook\n",
        "    df_events['timestamp_dt'] = pd.to_datetime(df_events['timestamp'])\n",
        "\n",
        "# 2. Sort Values\n",
        "# Sorting by visitor and time is CRITICAL. This ensures\n",
        "# that events for the same user are sequential before we calculate\n",
        "# the time difference between their actions.\n",
        "print(\"Sorting events by visitorid and timestamp...\")\n",
        "df_events.sort_values(by=['visitorid', 'timestamp_dt'], inplace=True)\n",
        "\n",
        "# 3. Calculate Time Difference\n",
        "# We define a session as a period of activity ending with\n",
        "# 30 minutes (1800 seconds) of inactivity.\n",
        "session_timeout_seconds = 30 * 60\n",
        "\n",
        "# We use groupby('visitorid').diff() to calculate the time (in seconds)\n",
        "# between consecutive events *for the same visitor*.\n",
        "# The first event for any visitor will result in 'NaT' (Not a Time).\n",
        "print(\"Calculating time difference between events for each visitor...\")\n",
        "df_events['time_diff_seconds'] = df_events.groupby('visitorid')['timestamp_dt'].diff().dt.total_seconds()\n",
        "\n",
        "# 4. Identify New Sessions\n",
        "# A new session starts when the time_diff is > our timeout,\n",
        "# OR when it's the very first event for that user (where time_diff is NaN/NaT).\n",
        "# We create a boolean flag 'new_session_flag' for this.\n",
        "df_events['new_session_flag'] = (df_events['time_diff_seconds'] > session_timeout_seconds) | (df_events['time_diff_seconds'].isnull())\n",
        "\n",
        "# 5. Assign Session IDs\n",
        "# We use cumsum() (cumulative sum) on the 'new_session_flag'\n",
        "# boolean (where True=1, False=0). This creates a unique, incrementing ID\n",
        "# for each new session within that visitor's group.\n",
        "print(\"Assigning unique session IDs...\")\n",
        "df_events['session_increment_id'] = df_events.groupby('visitorid')['new_session_flag'].cumsum()\n",
        "\n",
        "# Create a globally unique session_id by combining the visitorid\n",
        "# (as a string) with the session_increment_id. This will be our\n",
        "# primary key for the new session-feature matrix.\n",
        "df_events['session_id'] = df_events['visitorid'].astype(str) + '_' + df_events['session_increment_id'].astype(str)\n",
        "\n",
        "# 6. Report Results\n",
        "session_count = df_events['session_id'].nunique()\n",
        "visitor_count = df_events['visitorid'].nunique()\n",
        "avg_sessions_per_visitor = session_count / visitor_count\n",
        "avg_events_per_session = len(df_events) / session_count\n",
        "\n",
        "print(\"\\nSessionization Summary\")\n",
        "print(f\"Total events processed: {len(df_events):,}\")\n",
        "print(f\"Total unique visitors: {visitor_count:,}\")\n",
        "print(f\"Total unique sessions created: {session_count:,}\")\n",
        "print(f\"Average sessions per visitor: {avg_sessions_per_visitor:.2f}\")\n",
        "print(f\"Average events per session: {avg_events_per_session:.2f}\")\n",
        "\n",
        "# Display a sample of the sessionized data to verify\n",
        "print(\"\\nSample of sessionized data (showing new session flags):\")\n",
        "display(df_events[['timestamp_dt', 'visitorid', 'event', 'time_diff_seconds', 'new_session_flag', 'session_id']].head(10))\n",
        "\n",
        "# Clean up intermediate columns before next step\n",
        "df_events.drop(columns=['time_diff_seconds', 'new_session_flag', 'session_increment_id'], inplace=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eMbx4oc_qyqu"
      },
      "source": [
        "### Feature Engineering for Clustering\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i1myZrgrFQq8",
        "outputId": "dba821ee-29ff-4b8d-cd74-d9b35727c912"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Starting lookup map creation...\n",
            "Creating Item-to-Category map...\n",
            "Created item_category_map with 417,053 unique item-category pairs.\n",
            "Creating Item Availability map...\n",
            "Created item_availability_map with 1,503,639 availability records.\n",
            "Created category_name_map with 1,669 categories.\n",
            "\n",
            "Lookup map creation complete.\n",
            "The key dataframes for the next step are: 'item_category_map' and 'item_availability_map'.\n"
          ]
        }
      ],
      "source": [
        "print(\"Starting lookup map creation...\")\n",
        "\n",
        "# 1. Item-to-Category Map\n",
        "# We need a simple map of [itemid -> categoryid] to enrich both our\n",
        "# session features and our market baskets.\n",
        "print(\"Creating Item-to-Category map...\")\n",
        "item_category_map = df_properties[df_properties['property'] == 'categoryid'].copy()\n",
        "\n",
        "# The properties file can have multiple categories for the same item over time.\n",
        "# For simplicity, we'll take the *most recent* category entry for each item.\n",
        "item_category_map.sort_values(by=['itemid', 'timestamp'], ascending=[True, False], inplace=True)\n",
        "item_category_map = item_category_map.drop_duplicates(subset='itemid', keep='first')\n",
        "\n",
        "# Convert value to int for clean merging\n",
        "item_category_map['categoryid'] = item_category_map['value'].astype(int)\n",
        "item_category_map = item_category_map[['itemid', 'categoryid']]\n",
        "\n",
        "print(f\"Created item_category_map with {len(item_category_map):,} unique item-category pairs.\")\n",
        "\n",
        "# 2. Item Availability Map\n",
        "# This map will tell us if an item was in stock at the time\n",
        "# of an event. This is tricky because availability changes over time.\n",
        "print(\"Creating Item Availability map...\")\n",
        "item_availability_map = df_properties[df_properties['property'] == 'available'].copy()\n",
        "\n",
        "item_availability_map['is_available'] = item_availability_map['value'].astype(int)\n",
        "item_availability_map['timestamp_dt'] = pd.to_datetime(item_availability_map['timestamp'], unit='ms')\n",
        "\n",
        "item_availability_map = item_availability_map[['itemid', 'timestamp_dt', 'is_available']]\n",
        "\n",
        "# Sort by the keys we will merge on\n",
        "item_availability_map.sort_values(by=['itemid', 'timestamp_dt'], inplace=True)\n",
        "print(f\"Created item_availability_map with {len(item_availability_map):,} availability records.\")\n",
        "\n",
        "category_name_map = df_categories[['categoryid']].copy()\n",
        "# We could try to join parent names later if needed.\n",
        "print(f\"Created category_name_map with {len(category_name_map):,} categories.\")\n",
        "\n",
        "print(\"\\nLookup map creation complete.\")\n",
        "print(\"The key dataframes for the next step are: 'item_category_map' and 'item_availability_map'.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r9nlprPkrBVE",
        "outputId": "b24077a1-8044-4be7-deca-a058e4c6dace"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Starting rich feature engineering...\n",
            "Original df_events shape: (2756101, 7)\n",
            "Extracting time-based features (hour, day)...\n",
            "Enriching events with 'categoryid'...\n",
            "Enriching events with 'is_available' (using merge_asof)...\n",
            "Aggregating features by session_id...\n",
            "Pivoting event counts...\n",
            "Combining aggregated dataframes...\n",
            "Creating final ratio features...\n",
            "\n",
            " Feature Engineering Summary \n",
            "Final session_feature_matrix shape: (1761675, 16)\n",
            "\n",
            "Final Matrix Info:\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Index: 1761675 entries, 0_1 to 9_1\n",
            "Data columns (total 16 columns):\n",
            " #   Column                    Dtype         \n",
            "---  ------                    -----         \n",
            " 0   session_duration_sec      float64       \n",
            " 1   session_start_time        datetime64[ns]\n",
            " 2   total_events              int64         \n",
            " 3   unique_items_viewed       int64         \n",
            " 4   unique_categories_viewed  int64         \n",
            " 5   avg_item_availability     float64       \n",
            " 6   session_hour_of_day       int32         \n",
            " 7   session_day_of_week       int32         \n",
            " 8   addtocart_count           int64         \n",
            " 9   transaction_count         int64         \n",
            " 10  view_count                int64         \n",
            " 11  is_buyer                  int64         \n",
            " 12  event_rate_per_sec        float64       \n",
            " 13  view_to_cart_ratio        float64       \n",
            " 14  category_spread_ratio     float64       \n",
            " 15  is_weekend                int64         \n",
            "dtypes: datetime64[ns](1), float64(5), int32(2), int64(8)\n",
            "memory usage: 215.0+ MB\n",
            "\n",
            "Sample of final feature matrix (first 5 rows):\n",
            "            session_duration_sec      session_start_time  total_events  \\\n",
            "session_id                                                               \n",
            "0_1                      327.736 2015-09-11 20:49:49.439             3   \n",
            "1000000_1                  0.000 2015-06-05 18:16:10.629             1   \n",
            "1000001_1                  0.000 2015-07-07 18:12:14.953             1   \n",
            "1000001_2               1061.726 2015-07-24 20:18:15.303             3   \n",
            "1000001_3                  0.000 2015-07-29 20:38:29.170             1   \n",
            "\n",
            "            unique_items_viewed  unique_categories_viewed  \\\n",
            "session_id                                                  \n",
            "0_1                           3                         3   \n",
            "1000000_1                     1                         1   \n",
            "1000001_1                     1                         1   \n",
            "1000001_2                     3                         2   \n",
            "1000001_3                     1                         1   \n",
            "\n",
            "            avg_item_availability  session_hour_of_day  session_day_of_week  \\\n",
            "session_id                                                                    \n",
            "0_1                      0.333333                   20                    4   \n",
            "1000000_1                0.000000                   18                    4   \n",
            "1000001_1                0.000000                   18                    1   \n",
            "1000001_2                1.000000                   20                    4   \n",
            "1000001_3                1.000000                   20                    2   \n",
            "\n",
            "            addtocart_count  transaction_count  view_count  is_buyer  \\\n",
            "session_id                                                             \n",
            "0_1                       0                  0           3         0   \n",
            "1000000_1                 0                  0           1         0   \n",
            "1000001_1                 0                  0           1         0   \n",
            "1000001_2                 0                  0           3         0   \n",
            "1000001_3                 0                  0           1         0   \n",
            "\n",
            "            event_rate_per_sec  view_to_cart_ratio  category_spread_ratio  \\\n",
            "session_id                                                                  \n",
            "0_1                   0.009126                 0.0               1.000000   \n",
            "1000000_1             1.000000                 0.0               1.000000   \n",
            "1000001_1             1.000000                 0.0               1.000000   \n",
            "1000001_2             0.002823                 0.0               0.666667   \n",
            "1000001_3             1.000000                 0.0               1.000000   \n",
            "\n",
            "            is_weekend  \n",
            "session_id              \n",
            "0_1                  0  \n",
            "1000000_1            0  \n",
            "1000001_1            0  \n",
            "1000001_2            0  \n",
            "1000001_3            0  \n"
          ]
        }
      ],
      "source": [
        "print(\"Starting rich feature engineering...\")\n",
        "print(f\"Original df_events shape: {df_events.shape}\")\n",
        "\n",
        "# 1. Enrich Events\n",
        "# We add time-based features (day/hour) from the timestamp.\n",
        "# These will be aggregated to find time-of-day or day-of-week patterns.\n",
        "print(\"Extracting time-based features (hour, day)...\")\n",
        "df_events['session_hour_of_day'] = df_events['timestamp_dt'].dt.hour\n",
        "df_events['session_day_of_week'] = df_events['timestamp_dt'].dt.dayofweek\n",
        "\n",
        "# We do a left merge to add 'categoryid' to every event.\n",
        "# Events for items not in the properties file will have NaN.\n",
        "print(\"Enriching events with 'categoryid'...\")\n",
        "df_events_rich = pd.merge(df_events, item_category_map, on='itemid', how='left')\n",
        "\n",
        "# This is the time-sensitive merge. We use pd.merge_asof()\n",
        "# to join each event with the *last known availability* status *before*\n",
        "# that event occurred.\n",
        "# We must sort both dataframes by the merge keys ('itemid', 'timestamp_dt').\n",
        "print(\"Enriching events with 'is_available' (using merge_asof)...\")\n",
        "df_events_rich = pd.merge_asof(\n",
        "    df_events_rich.sort_values('timestamp_dt'),\n",
        "    item_availability_map.sort_values('timestamp_dt'),\n",
        "    on='timestamp_dt',\n",
        "    by='itemid',\n",
        "    direction='backward' # Finds the last known value before the event\n",
        ")\n",
        "\n",
        "# After the merge, 'is_available' will be NaN for items with no\n",
        "# availability data. We'll assume these items are unavailable (0).\n",
        "df_events_rich['is_available'] = df_events_rich['is_available'].fillna(0).astype(int)\n",
        "\n",
        "\n",
        "# 2. Aggregate Session-Level Features\n",
        "# Now we group by 'session_id' and aggregate all event-level\n",
        "# data into a single row per session.\n",
        "print(\"Aggregating features by session_id...\")\n",
        "agg_dict = {\n",
        "    'timestamp_dt': [lambda x: (x.max() - x.min()).total_seconds(), 'min'], # Duration and start time\n",
        "    'event': 'count',                 # total_events\n",
        "    'itemid': 'nunique',              # unique_items_viewed\n",
        "    'categoryid': 'nunique',          # unique_categories_viewed\n",
        "    'is_available': 'mean',           # avg_item_availability\n",
        "    'session_hour_of_day': 'first',   # Time of session start\n",
        "    'session_day_of_week': 'first'    # Day of session start\n",
        "}\n",
        "\n",
        "session_features = df_events_rich.groupby('session_id').agg(agg_dict)\n",
        "\n",
        "# Flatten the multi-index columns created by .agg()\n",
        "session_features.columns = ['session_duration_sec', 'session_start_time',\n",
        "                            'total_events', 'unique_items_viewed',\n",
        "                            'unique_categories_viewed', 'avg_item_availability',\n",
        "                            'session_hour_of_day', 'session_day_of_week']\n",
        "\n",
        "\n",
        "# 3. Pivot Event Counts\n",
        "#  We need specific counts for 'view', 'addtocart', and 'transaction'\n",
        "# to build our ratio features and identify buyers.\n",
        "print(\"Pivoting event counts...\")\n",
        "event_counts = df_events_rich.groupby('session_id')['event'].value_counts().unstack(fill_value=0)\n",
        "\n",
        "# Rename columns for clarity.\n",
        "event_counts.columns = [col + '_count' for col in event_counts.columns]\n",
        "\n",
        "# Ensure all three columns exist, even if one event type (like 'transaction')\n",
        "# didn't happen in any session (unlikely, but safe)\n",
        "for col in ['view_count', 'addtocart_count', 'transaction_count']:\n",
        "    if col not in event_counts.columns:\n",
        "        event_counts[col] = 0\n",
        "\n",
        "# Create our key target variable, 'is_buyer'.\n",
        "event_counts['is_buyer'] = (event_counts['transaction_count'] > 0).astype(int)\n",
        "\n",
        "\n",
        "# 4. Combine and Create Final Ratio Features\n",
        "#  Merge our two aggregated dataframes to create the final matrix.\n",
        "print(\"Combining aggregated dataframes...\")\n",
        "session_feature_matrix = pd.merge(session_features, event_counts, on='session_id', how='left')\n",
        "\n",
        "# Create the final ratio features based on our plan.\n",
        "# We handle division by zero (e.g., sessions with 0 duration or 0 views)\n",
        "# by replacing resulting 'inf' or 'NaN' values with 0.\n",
        "print(\"Creating final ratio features...\")\n",
        "\n",
        "# Event rate (how fast the user is clicking)\n",
        "session_feature_matrix['event_rate_per_sec'] = (\n",
        "    session_feature_matrix['total_events'] / (session_feature_matrix['session_duration_sec'] + 1) # +1 to avoid 0s\n",
        ").fillna(0)\n",
        "\n",
        "# View-to-cart ratio (micro-conversion)\n",
        "session_feature_matrix['view_to_cart_ratio'] = (\n",
        "    session_feature_matrix['addtocart_count'] / session_feature_matrix['view_count']\n",
        ").fillna(0).replace(np.inf, 0)\n",
        "\n",
        "# Category spread (focused vs. broad browser)\n",
        "session_feature_matrix['category_spread_ratio'] = (\n",
        "    session_feature_matrix['unique_categories_viewed'] / session_feature_matrix['unique_items_viewed']\n",
        ").fillna(0).replace(np.inf, 0)\n",
        "\n",
        "# Is weekend\n",
        "session_feature_matrix['is_weekend'] = (\n",
        "    session_feature_matrix['session_day_of_week'].isin([5, 6])\n",
        ").astype(int)\n",
        "\n",
        "# 5. Report Results\n",
        "print(\"\\n Feature Engineering Summary \")\n",
        "print(f\"Final session_feature_matrix shape: {session_feature_matrix.shape}\")\n",
        "print(\"\\nFinal Matrix Info:\")\n",
        "session_feature_matrix.info()\n",
        "print(\"\\nSample of final feature matrix (first 5 rows):\")\n",
        "print(session_feature_matrix.head())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 361
        },
        "id": "bF79qL3asa3E",
        "outputId": "d7e47dcb-a33e-4d5e-8976-fab330f03a7c"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "summary": "{\n  \"name\": \"print(f\\\"Features session matrix data saved to '{BASE_DIR}/session_feature_matrix\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"session_id\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"1000000_1\",\n          \"1000001_3\",\n          \"1000001_1\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"session_duration_sec\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 460.5844262681925,\n        \"min\": 0.0,\n        \"max\": 1061.726,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          327.736,\n          0.0,\n          1061.726\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"session_start_time\",\n      \"properties\": {\n        \"dtype\": \"date\",\n        \"min\": \"2015-06-05 18:16:10.629000\",\n        \"max\": \"2015-09-11 20:49:49.439000\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"2015-06-05 18:16:10.629000\",\n          \"2015-07-29 20:38:29.170000\",\n          \"2015-07-07 18:12:14.953000\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"total_events\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 1,\n        \"max\": 3,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          3\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"unique_items_viewed\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 1,\n        \"max\": 3,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          3\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"unique_categories_viewed\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 1,\n        \"max\": 3,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          3,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"avg_item_availability\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.5055250296034367,\n        \"min\": 0.0,\n        \"max\": 1.0,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0.3333333333333333,\n          0.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"session_hour_of_day\",\n      \"properties\": {\n        \"dtype\": \"int32\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          18,\n          20\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"session_day_of_week\",\n      \"properties\": {\n        \"dtype\": \"int32\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          4,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"addtocart_count\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 0,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"transaction_count\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 0,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"view_count\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 1,\n        \"max\": 3,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"is_buyer\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 0,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"event_rate_per_sec\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.5444548062378387,\n        \"min\": 0.0028229289581698383,\n        \"max\": 1.0,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0.009125863915117298\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"view_to_cart_ratio\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0,\n        \"min\": 0.0,\n        \"max\": 0.0,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"category_spread_ratio\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.149071198499986,\n        \"min\": 0.6666666666666666,\n        \"max\": 1.0,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0.6666666666666666\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"is_weekend\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 0,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
              "type": "dataframe"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-b6a7f9a8-eeae-492e-904a-b55e7e3f76fa\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>session_duration_sec</th>\n",
              "      <th>session_start_time</th>\n",
              "      <th>total_events</th>\n",
              "      <th>unique_items_viewed</th>\n",
              "      <th>unique_categories_viewed</th>\n",
              "      <th>avg_item_availability</th>\n",
              "      <th>session_hour_of_day</th>\n",
              "      <th>session_day_of_week</th>\n",
              "      <th>addtocart_count</th>\n",
              "      <th>transaction_count</th>\n",
              "      <th>view_count</th>\n",
              "      <th>is_buyer</th>\n",
              "      <th>event_rate_per_sec</th>\n",
              "      <th>view_to_cart_ratio</th>\n",
              "      <th>category_spread_ratio</th>\n",
              "      <th>is_weekend</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>session_id</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0_1</th>\n",
              "      <td>327.736</td>\n",
              "      <td>2015-09-11 20:49:49.439</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>20</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0.009126</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1000000_1</th>\n",
              "      <td>0.000</td>\n",
              "      <td>2015-06-05 18:16:10.629</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>18</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1000001_1</th>\n",
              "      <td>0.000</td>\n",
              "      <td>2015-07-07 18:12:14.953</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>18</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1000001_2</th>\n",
              "      <td>1061.726</td>\n",
              "      <td>2015-07-24 20:18:15.303</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>20</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0.002823</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1000001_3</th>\n",
              "      <td>0.000</td>\n",
              "      <td>2015-07-29 20:38:29.170</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>20</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b6a7f9a8-eeae-492e-904a-b55e7e3f76fa')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-b6a7f9a8-eeae-492e-904a-b55e7e3f76fa button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-b6a7f9a8-eeae-492e-904a-b55e7e3f76fa');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-130e1062-ebf3-4cf0-93da-6590c11be5b2\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-130e1062-ebf3-4cf0-93da-6590c11be5b2')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-130e1062-ebf3-4cf0-93da-6590c11be5b2 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "            session_duration_sec      session_start_time  total_events  \\\n",
              "session_id                                                               \n",
              "0_1                      327.736 2015-09-11 20:49:49.439             3   \n",
              "1000000_1                  0.000 2015-06-05 18:16:10.629             1   \n",
              "1000001_1                  0.000 2015-07-07 18:12:14.953             1   \n",
              "1000001_2               1061.726 2015-07-24 20:18:15.303             3   \n",
              "1000001_3                  0.000 2015-07-29 20:38:29.170             1   \n",
              "\n",
              "            unique_items_viewed  unique_categories_viewed  \\\n",
              "session_id                                                  \n",
              "0_1                           3                         3   \n",
              "1000000_1                     1                         1   \n",
              "1000001_1                     1                         1   \n",
              "1000001_2                     3                         2   \n",
              "1000001_3                     1                         1   \n",
              "\n",
              "            avg_item_availability  session_hour_of_day  session_day_of_week  \\\n",
              "session_id                                                                    \n",
              "0_1                      0.333333                   20                    4   \n",
              "1000000_1                0.000000                   18                    4   \n",
              "1000001_1                0.000000                   18                    1   \n",
              "1000001_2                1.000000                   20                    4   \n",
              "1000001_3                1.000000                   20                    2   \n",
              "\n",
              "            addtocart_count  transaction_count  view_count  is_buyer  \\\n",
              "session_id                                                             \n",
              "0_1                       0                  0           3         0   \n",
              "1000000_1                 0                  0           1         0   \n",
              "1000001_1                 0                  0           1         0   \n",
              "1000001_2                 0                  0           3         0   \n",
              "1000001_3                 0                  0           1         0   \n",
              "\n",
              "            event_rate_per_sec  view_to_cart_ratio  category_spread_ratio  \\\n",
              "session_id                                                                  \n",
              "0_1                   0.009126                 0.0               1.000000   \n",
              "1000000_1             1.000000                 0.0               1.000000   \n",
              "1000001_1             1.000000                 0.0               1.000000   \n",
              "1000001_2             0.002823                 0.0               0.666667   \n",
              "1000001_3             1.000000                 0.0               1.000000   \n",
              "\n",
              "            is_weekend  \n",
              "session_id              \n",
              "0_1                  0  \n",
              "1000000_1            0  \n",
              "1000001_1            0  \n",
              "1000001_2            0  \n",
              "1000001_3            0  "
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Features session matrix data saved to '/content/drive/MyDrive/UP Honours/COS781 -Data Mining/Project/session_feature_matrix.csv'.\n"
          ]
        }
      ],
      "source": [
        "# Features\n",
        "print(\"Starting rich feature engineering...\")\n",
        "print(f\"Original df_events shape: {df_events.shape}\")\n",
        "\n",
        "# 1. Enrich Events\n",
        "# We add time-based features (day/hour) from the timestamp.\n",
        "# These will be aggregated to find time-of-day or day-of-week patterns.\n",
        "print(\"Extracting time-based features (hour, day)...\")\n",
        "df_events['session_hour_of_day'] = df_events['timestamp_dt'].dt.hour\n",
        "df_events['session_day_of_week'] = df_events['timestamp_dt'].dt.dayofweek\n",
        "\n",
        "# We do a left merge to add 'categoryid' to every event.\n",
        "# Events for items not in the properties file will have NaN.\n",
        "print(\"Enriching events with 'categoryid'...\")\n",
        "df_events_rich = pd.merge(df_events, item_category_map, on='itemid', how='left')\n",
        "\n",
        "# This is the time-sensitive merge. We use pd.merge_asof()\n",
        "# to join each event with the *last known availability* status *before*\n",
        "# that event occurred.\n",
        "# We must sort both dataframes by the merge keys ('itemid', 'timestamp_dt').\n",
        "print(\"Enriching events with 'is_available' (using merge_asof)...\")\n",
        "df_events_rich = pd.merge_asof(\n",
        "    df_events_rich.sort_values('timestamp_dt'),\n",
        "    item_availability_map.sort_values('timestamp_dt'),\n",
        "    on='timestamp_dt',\n",
        "    by='itemid',\n",
        "    direction='backward' # Finds the last known value before the event\n",
        ")\n",
        "\n",
        "# After the merge, 'is_available' will be NaN for items with no\n",
        "# availability data. We'll assume these items are unavailable (0).\n",
        "df_events_rich['is_available'] = df_events_rich['is_available'].fillna(0).astype(int)\n",
        "\n",
        "# 2. Aggregate Session-Level Features\n",
        "# Now we group by 'session_id' and aggregate all event-level\n",
        "# data into a single row per session.\n",
        "print(\"Aggregating features by session_id...\")\n",
        "agg_dict = {\n",
        "    'timestamp_dt': [lambda x: (x.max() - x.min()).total_seconds(), 'min'], # Duration and start time\n",
        "    'event': 'count',                 # total_events\n",
        "    'itemid': 'nunique',              # unique_items_viewed\n",
        "    'categoryid': 'nunique',          # unique_categories_viewed\n",
        "    'is_available': 'mean',           # avg_item_availability\n",
        "    'session_hour_of_day': 'first',   # Time of session start\n",
        "    'session_day_of_week': 'first'    # Day of session start\n",
        "}\n",
        "\n",
        "session_features = df_events_rich.groupby('session_id').agg(agg_dict)\n",
        "\n",
        "# Flatten the multi-index columns created by .agg()\n",
        "session_features.columns = ['session_duration_sec', 'session_start_time',\n",
        "                            'total_events', 'unique_items_viewed',\n",
        "                            'unique_categories_viewed', 'avg_item_availability',\n",
        "                            'session_hour_of_day', 'session_day_of_week']\n",
        "\n",
        "\n",
        "# 3. Pivot Event Counts ---\n",
        "#  We need specific counts for 'view', 'addtocart', and 'transaction'\n",
        "# to build our ratio features and identify buyers.\n",
        "print(\"Pivoting event counts...\")\n",
        "event_counts = df_events_rich.groupby('session_id')['event'].value_counts().unstack(fill_value=0)\n",
        "\n",
        "#  Rename columns for clarity.\n",
        "event_counts.columns = [col + '_count' for col in event_counts.columns]\n",
        "\n",
        "# Ensure all three columns exist, even if one event type (like 'transaction')\n",
        "# didn't happen in any session (unlikely, but safe)\n",
        "for col in ['view_count', 'addtocart_count', 'transaction_count']:\n",
        "    if col not in event_counts.columns:\n",
        "        event_counts[col] = 0\n",
        "\n",
        "#  Create our key target variable, 'is_buyer'.\n",
        "event_counts['is_buyer'] = (event_counts['transaction_count'] > 0).astype(int)\n",
        "\n",
        "\n",
        "# --- 4. Combine and Create Final Ratio Features ---\n",
        "#  Merge our two aggregated dataframes to create the final matrix.\n",
        "print(\"Combining aggregated dataframes...\")\n",
        "session_feature_matrix = pd.merge(session_features, event_counts, on='session_id', how='left')\n",
        "\n",
        "#  Create the final ratio features based on our plan.\n",
        "# We handle division by zero (e.g., sessions with 0 duration or 0 views)\n",
        "# by replacing resulting 'inf' or 'NaN' values with 0.\n",
        "print(\"Creating final ratio features...\")\n",
        "\n",
        "# Event rate (how fast the user is clicking)\n",
        "session_feature_matrix['event_rate_per_sec'] = (\n",
        "    session_feature_matrix['total_events'] / (session_feature_matrix['session_duration_sec'] + 1) # +1 to avoid 0s\n",
        ").fillna(0)\n",
        "\n",
        "# View-to-cart ratio (micro-conversion)\n",
        "session_feature_matrix['view_to_cart_ratio'] = (\n",
        "    session_feature_matrix['addtocart_count'] / session_feature_matrix['view_count']\n",
        ").fillna(0).replace(np.inf, 0)\n",
        "\n",
        "# Category spread (focused vs. broad browser)\n",
        "session_feature_matrix['category_spread_ratio'] = (\n",
        "    session_feature_matrix['unique_categories_viewed'] / session_feature_matrix['unique_items_viewed']\n",
        ").fillna(0).replace(np.inf, 0)\n",
        "\n",
        "# Is weekend\n",
        "session_feature_matrix['is_weekend'] = (\n",
        "    session_feature_matrix['session_day_of_week'].isin([5, 6])\n",
        ").astype(int)\n",
        "\n",
        "# --- 5. Report Results ---\n",
        "print(\"\\n--- Feature Engineering Summary ---\")\n",
        "print(f\"Final session_feature_matrix shape: {session_feature_matrix.shape}\")\n",
        "print(\"\\nFinal Matrix Info:\")\n",
        "session_feature_matrix.info()\n",
        "print(\"\\nSample of final feature matrix (first 5 rows):\")\n",
        "print(session_feature_matrix.head())\n",
        "\n",
        "display(session_feature_matrix.head())\n",
        "\n",
        "session_feature_matrix.to_csv(f'{OUTPUTS_DIR}/session_feature_matrix.csv')\n",
        "print(f\"Features session matrix data saved to '{OUTPUTS_DIR}/session_feature_matrix.csv'.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A8F4YCKhtwoR",
        "outputId": "c3bbfbd9-fbcd-43e5-e6be-dd0682002c38"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Starting data scaling for K-Means...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-2304352175.py:34: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  X.replace([np.inf, -np.inf], 0, inplace=True)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Scaling features using StandardScaler...\n",
            "\n",
            "--- Scaling Summary ---\n",
            "Data scaled successfully. Shape: (1722864, 12)\n",
            "\n",
            "Sample of scaled data:\n",
            "            session_duration_sec  total_events  unique_items_viewed  \\\n",
            "session_id                                                            \n",
            "0_1                     0.747928      1.016926             1.725313   \n",
            "1000000_1              -0.269207     -0.314189            -0.269693   \n",
            "1000001_1              -0.269207     -0.314189            -0.269693   \n",
            "1000001_2               3.025881      1.016926             1.725313   \n",
            "1000001_3              -0.269207     -0.314189            -0.269693   \n",
            "\n",
            "            unique_categories_viewed  avg_item_availability  \\\n",
            "session_id                                                    \n",
            "0_1                         4.372708              -0.127893   \n",
            "1000000_1                   0.147813              -0.827871   \n",
            "1000001_1                   0.147813              -0.827871   \n",
            "1000001_2                   2.260261               1.272064   \n",
            "1000001_3                   0.147813               1.272064   \n",
            "\n",
            "            session_hour_of_day  view_count  addtocart_count  \\\n",
            "session_id                                                     \n",
            "0_1                    0.934287    1.121571        -0.115163   \n",
            "1000000_1              0.679795   -0.308642        -0.115163   \n",
            "1000001_1              0.679795   -0.308642        -0.115163   \n",
            "1000001_2              0.934287    1.121571        -0.115163   \n",
            "1000001_3              0.934287   -0.308642        -0.115163   \n",
            "\n",
            "            event_rate_per_sec  view_to_cart_ratio  category_spread_ratio  \\\n",
            "session_id                                                                  \n",
            "0_1                  -2.008607           -0.102772               0.531256   \n",
            "1000000_1             0.506334           -0.102772               0.531256   \n",
            "1000001_1             0.506334           -0.102772               0.531256   \n",
            "1000001_2            -2.024604           -0.102772              -0.417538   \n",
            "1000001_3             0.506334           -0.102772               0.531256   \n",
            "\n",
            "            is_weekend  \n",
            "session_id              \n",
            "0_1          -0.557329  \n",
            "1000000_1    -0.557329  \n",
            "1000001_1    -0.557329  \n",
            "1000001_2    -0.557329  \n",
            "1000001_3    -0.557329  \n",
            "\n",
            "--- MILESTONE 1 (PREPROCESSING) COMPLETE ---\n",
            "You are now ready for Milestone 2: K-Means Clustering.\n",
            "Scaled data saved to '/content/drive/MyDrive/UP Honours/COS781 -Data Mining/Project/session_feature_matrix_scaled.csv'.\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Load Data\n",
        "# Assuming 'session_feature_matrix' is in memory from Step 4.\n",
        "\n",
        "print(\"Starting data scaling for K-Means...\")\n",
        "\n",
        "# 1. Select Features for Clustering\n",
        "#  We will select only the numerical features that describe\n",
        "# session *behavior*. We exclude non-behavioral columns like\n",
        "# 'session_start_time' and 'is_buyer' (which we'll use later for profiling,\n",
        "# not for the clustering itself).\n",
        "features_for_clustering = [\n",
        "    'session_duration_sec',\n",
        "    'total_events',\n",
        "    'unique_items_viewed',\n",
        "    'unique_categories_viewed',\n",
        "    'avg_item_availability',\n",
        "    'session_hour_of_day',\n",
        "    'view_count',\n",
        "    'addtocart_count',\n",
        "    'event_rate_per_sec',\n",
        "    'view_to_cart_ratio',\n",
        "    'category_spread_ratio',\n",
        "    'is_weekend'\n",
        "]\n",
        "\n",
        "# Create the final matrix for clustering\n",
        "X = session_feature_matrix[features_for_clustering]\n",
        "\n",
        "#  Handle any potential inf/-inf values that might have resulted\n",
        "# from division, just in case.\n",
        "X.replace([np.inf, -np.inf], 0, inplace=True)\n",
        "\n",
        "\n",
        "# 2. Scale the Data\n",
        "#  We use StandardScaler to transform the data so that each\n",
        "# feature has a mean of 0 and a standard deviation of 1. This\n",
        "# standardizes their importance for the K-Means algorithm.\n",
        "print(\"Scaling features using StandardScaler...\")\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "# Convert back to a DataFrame for easier handling\n",
        "X_scaled_df = pd.DataFrame(X_scaled, columns=X.columns, index=X.index)\n",
        "\n",
        "# 3. Report Results\n",
        "print(\"\\n--- Scaling Summary ---\")\n",
        "print(f\"Data scaled successfully. Shape: {X_scaled_df.shape}\")\n",
        "print(\"\\nSample of scaled data:\")\n",
        "print(X_scaled_df.head())\n",
        "\n",
        "\n",
        "# Save the scaled data for the next notebook\n",
        "X_scaled_df.to_csv(f'{OUTPUTS_DIR}/session_feature_matrix_scaled.csv')\n",
        "print(f\"Scaled data saved to '{OUTPUTS_DIR}/session_feature_matrix_scaled.csv'.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IDfMPXE7Agpo"
      },
      "outputs": [],
      "source": [
        "# 1. Session Duration Distribution\n",
        "sns.histplot(session_feature_matrix['session_duration_sec'], bins=50, kde=True)\n",
        "plt.title(\"Distribution of Session Duration (sec)\")\n",
        "plt.xlabel(\"Session Duration (sec)\"); plt.ylabel(\"Frequency\")\n",
        "plt.show()\n",
        "\n",
        "# 2. Session Start Time Heatmap\n",
        "pd.crosstab(session_feature_matrix['session_day_of_week'], session_feature_matrix['session_hour_of_day']) \\\n",
        "  .pipe(lambda df: sns.heatmap(df, cmap=\"YlGnBu\"))\n",
        "plt.title(\"Sessions by Hour and Day of Week\")\n",
        "plt.show()\n",
        "\n",
        "# 3. Buyer vs. Non-Buyer Boxplot\n",
        "sns.boxplot(x=\"is_buyer\", y=\"view_to_cart_ratio\", data=session_feature_matrix)\n",
        "plt.title(\"View-to-Cart Ratio: Buyer vs. Non-Buyer\")\n",
        "plt.show()\n",
        "\n",
        "# 4. Correlation Heatmap\n",
        "corr = session_feature_matrix.corr()\n",
        "sns.heatmap(corr, annot=True, fmt=\".2f\", cmap=\"coolwarm\")\n",
        "plt.title(\"Feature Correlation Heatmap\")\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "data-mining",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.19"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
